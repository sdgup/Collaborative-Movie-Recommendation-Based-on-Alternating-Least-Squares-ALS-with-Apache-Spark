{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZHM3HHHR7A2"
   },
   "source": [
    "In this project we will be working with Movie Lens dataset and will try to build a recomendation system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLf6kHYvI2op"
   },
   "source": [
    "# Importing all essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/spark2.4.3\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/local/anaconda/bin/python\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/local/anaconda/bin/python\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "#import required libraries\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import gmplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import seaborn as sns\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "# Import libraries and other functions\n",
    "from io import StringIO\n",
    "from collections import namedtuple\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import sum, col, desc\n",
    "\n",
    "# ML lib\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import TrainValidationSplit,ParamGridBuilder\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asHN-eypT7oX"
   },
   "source": [
    "# Creating spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LrXBcdSAF6Lp"
   },
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"Recomendation\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing csv files into Jupyter notebook from HDFS --START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gs584Zh8Fagz"
   },
   "outputs": [],
   "source": [
    "#importing rating dataset\n",
    "df_ratings= spark.read.csv('hdfs:///user/imat5322_376434/ratings.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iVAFKLuVm6VO"
   },
   "outputs": [],
   "source": [
    "#importing movie dataset\n",
    "\n",
    "df_movies=spark.read.csv('hdfs:///user/imat5322_376434/movies.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing links dataset\n",
    "\n",
    "df_links=spark.read.csv('hdfs:///user/imat5322_376434/links.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing movie metadata dataset - additional metadata file\n",
    "\n",
    "df_movies_metadata=spark.read.csv('hdfs:///user/imat5322_376434/movies_metadata.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing language code dataset - additional metadata file\n",
    "\n",
    "df_language_codes=spark.read.csv('hdfs:///user/imat5322_376434/language_codes.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Pixiedust for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.15, Latest is 1.1.19</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Please restart kernel after upgrading.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pixiedust.display import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(df_links.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OPDDVtwnFlX",
    "outputId": "1416d2c8-cf43-4f6c-89ef-d8a346337c7d"
   },
   "outputs": [],
   "source": [
    "#df_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records = 58098\n",
      "Total columns = 3\n",
      "+++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++\n",
      "1.Column<b'movieId'>\n",
      "  Missing Values = \n",
      "+------------------------------------------------+\n",
      "|count(CASE WHEN (movieId IS NULL) THEN true END)|\n",
      "+------------------------------------------------+\n",
      "|                                               0|\n",
      "+------------------------------------------------+\n",
      "\n",
      "2.Column<b'title'>\n",
      "  Missing Values = \n",
      "+----------------------------------------------+\n",
      "|count(CASE WHEN (title IS NULL) THEN true END)|\n",
      "+----------------------------------------------+\n",
      "|                                             0|\n",
      "+----------------------------------------------+\n",
      "\n",
      "3.Column<b'genres'>\n",
      "  Missing Values = \n",
      "+-----------------------------------------------+\n",
      "|count(CASE WHEN (genres IS NULL) THEN true END)|\n",
      "+-----------------------------------------------+\n",
      "|                                              0|\n",
      "+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize Counter to 0\n",
    "i = 0 \n",
    "\n",
    "#Total records in the df_movies dataframe\n",
    "\n",
    "total = df_movies.count()\n",
    "\n",
    "print(\"Total Records = \" + str(total))\n",
    "\n",
    "#Prints the total number of column\n",
    "\n",
    "print(\"Total columns = \" + str(len(df_movies.columns)))\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "#while Loop used here to display the count of  each column's missing values \n",
    "\n",
    "while i < len(df_movies.columns):                             \n",
    "#Loop which checks every column\n",
    "    print(str(i+1) + \".\" + str(df_movies[i]))\n",
    "    print(\"  Missing Values = \") \n",
    "   \n",
    "    missingvalue1 = df_movies.select([count(when(df_movies[i].isNull(),True))]).show() \n",
    "    i = i+1 \n",
    "    #Counter is incremented by 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- adult: string (nullable = true)\n",
      " |-- belongs_to_collection: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- video: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies_metadata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [],
   "source": [
    "#display(df_language_codes.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records = 9139592\n",
      "Total columns = 4\n",
      "+++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++\n",
      "1.Column<b'userId'>\n",
      "  Missing Values = \n",
      "+-----------------------------------------------+\n",
      "|count(CASE WHEN (userId IS NULL) THEN true END)|\n",
      "+-----------------------------------------------+\n",
      "|                                              0|\n",
      "+-----------------------------------------------+\n",
      "\n",
      "2.Column<b'movieId'>\n",
      "  Missing Values = \n",
      "+------------------------------------------------+\n",
      "|count(CASE WHEN (movieId IS NULL) THEN true END)|\n",
      "+------------------------------------------------+\n",
      "|                                               0|\n",
      "+------------------------------------------------+\n",
      "\n",
      "3.Column<b'rating'>\n",
      "  Missing Values = \n",
      "+-----------------------------------------------+\n",
      "|count(CASE WHEN (rating IS NULL) THEN true END)|\n",
      "+-----------------------------------------------+\n",
      "|                                              0|\n",
      "+-----------------------------------------------+\n",
      "\n",
      "4.Column<b'timestamp'>\n",
      "  Missing Values = \n",
      "+--------------------------------------------------+\n",
      "|count(CASE WHEN (timestamp IS NULL) THEN true END)|\n",
      "+--------------------------------------------------+\n",
      "|                                                 0|\n",
      "+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize Counter to 0\n",
    "i = 0 \n",
    "\n",
    "#Total records in the df_ratings dataframe\n",
    "\n",
    "total = df_ratings.count()\n",
    "\n",
    "print(\"Total Records = \" + str(total))\n",
    "\n",
    "#Prints the total number of column\n",
    "\n",
    "print(\"Total columns = \" + str(len(df_ratings.columns)))\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "# while Loop used here to display the count of  \n",
    "# each column's missing values \n",
    "\n",
    "while i < len(df_ratings.columns):                             \n",
    "#Loop which checks every column\n",
    "    print(str(i+1) + \".\" + str(df_ratings[i]))\n",
    "    print(\"  Missing Values = \") \n",
    "   \n",
    "    missingvalue1 = df_ratings \\\n",
    "    .select([count(when(df_ratings[i].isNull(),True))]).show() \n",
    "    i = i+1 \n",
    "    #Counter is incremented by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies metadata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_movies_metadata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_movies_metadata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records = 184\n",
      "Total columns = 2\n",
      "+++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++\n",
      "1.Column<b'userId'>\n",
      "  Missing Values = \n",
      "+---------------------------------------------+\n",
      "|count(CASE WHEN (code IS NULL) THEN true END)|\n",
      "+---------------------------------------------+\n",
      "|                                            0|\n",
      "+---------------------------------------------+\n",
      "\n",
      "2.Column<b'movieId'>\n",
      "  Missing Values = \n",
      "+-------------------------------------------------+\n",
      "|count(CASE WHEN (language IS NULL) THEN true END)|\n",
      "+-------------------------------------------------+\n",
      "|                                                0|\n",
      "+-------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize Counter to 0\n",
    "i = 0 \n",
    "\n",
    "#Total records in the df_ratings dataframe\n",
    "\n",
    "total = df_language_codes.count()\n",
    "\n",
    "print(\"Total Records = \" + str(total))\n",
    "\n",
    "#Prints the total number of column\n",
    "\n",
    "print(\"Total columns = \" + str(len(df_language_codes.columns)))\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "# while Loop used here to display the count of  \n",
    "# each column's missing values \n",
    "\n",
    "while i < len(df_language_codes.columns):                             \n",
    "#Loop which checks every column\n",
    "    print(str(i+1) + \".\" + str(df_ratings[i]))\n",
    "    print(\"  Missing Values = \") \n",
    "   \n",
    "    missingvalue1 = df_language_codes \\\n",
    "    .select([count(when(df_language_codes[i].isNull(),True))]).show() \n",
    "    i = i+1 \n",
    "    #Counter is incremented by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently we are not working with df_language_code dataframe. We will use it at appropriate place. This dataset is small and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and pre-prossesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and pre-processing of df_ratings dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   3.5|1256677221|\n",
      "|     1|    481|   3.5|1256677456|\n",
      "|     1|   1091|   1.5|1256677471|\n",
      "|     1|   1257|   4.5|1256677460|\n",
      "|     1|   1449|   4.5|1256677264|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+-------------------+\n",
      "|userId|movieId|rating| timestamp|     Date_of_rating|\n",
      "+------+-------+------+----------+-------------------+\n",
      "|     1|    307|   3.5|1256677221|2009-10-27 21:00:21|\n",
      "|     1|    481|   3.5|1256677456|2009-10-27 21:04:16|\n",
      "|     1|   1091|   1.5|1256677471|2009-10-27 21:04:31|\n",
      "|     1|   1257|   4.5|1256677460|2009-10-27 21:04:20|\n",
      "|     1|   1449|   4.5|1256677264|2009-10-27 21:01:04|\n",
      "|     1|   1590|   2.5|1256677236|2009-10-27 21:00:36|\n",
      "|     1|   1591|   1.5|1256677475|2009-10-27 21:04:35|\n",
      "|     1|   2134|   4.5|1256677464|2009-10-27 21:04:24|\n",
      "|     1|   2478|   4.0|1256677239|2009-10-27 21:00:39|\n",
      "|     1|   2840|   3.0|1256677500|2009-10-27 21:05:00|\n",
      "|     1|   2986|   2.5|1256677496|2009-10-27 21:04:56|\n",
      "|     1|   3020|   4.0|1256677260|2009-10-27 21:01:00|\n",
      "|     1|   3424|   4.5|1256677444|2009-10-27 21:04:04|\n",
      "|     1|   3698|   3.5|1256677243|2009-10-27 21:00:43|\n",
      "|     1|   3826|   2.0|1256677210|2009-10-27 21:00:10|\n",
      "|     1|   3893|   3.5|1256677486|2009-10-27 21:04:46|\n",
      "|     2|    170|   3.5|1192913581|2007-10-20 20:53:01|\n",
      "|     2|    849|   3.5|1192913537|2007-10-20 20:52:17|\n",
      "|     2|   1186|   3.5|1192913611|2007-10-20 20:53:31|\n",
      "|     2|   1235|   3.0|1192913585|2007-10-20 20:53:05|\n",
      "+------+-------+------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#converting timestamp to actual date\n",
    "\n",
    "df_ratings = (df_ratings.select(\"userId\",\"movieId\",\"rating\",\"timestamp\") \\\n",
    "              .withColumn(\"Date_of_rating\", from_unixtime(\"timestamp\")))\n",
    "df_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the year,month, date, hour data from the Date_of_rating\n",
    "\n",
    "df_ratings_final = df_ratings \\\n",
    ".withColumn(\"year\",expr(\"substring(Date_of_rating, 1, 4)\")) \\\n",
    ".withColumn(\"month\",expr(\"substring(Date_of_rating, 6, 2)\")) \\\n",
    ".withColumn(\"date\",expr(\"substring(Date_of_rating, 9, 2)\")) \\\n",
    ".withColumn(\"hour\",expr(\"substring(Date_of_rating, 12, 2)\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+-------------------+----+-----+----+----+\n",
      "|userId|movieId|rating| timestamp|     Date_of_rating|year|month|date|hour|\n",
      "+------+-------+------+----------+-------------------+----+-----+----+----+\n",
      "|     1|    307|   3.5|1256677221|2009-10-27 21:00:21|2009|   10|  27|  21|\n",
      "|     1|    481|   3.5|1256677456|2009-10-27 21:04:16|2009|   10|  27|  21|\n",
      "|     1|   1091|   1.5|1256677471|2009-10-27 21:04:31|2009|   10|  27|  21|\n",
      "|     1|   1257|   4.5|1256677460|2009-10-27 21:04:20|2009|   10|  27|  21|\n",
      "|     1|   1449|   4.5|1256677264|2009-10-27 21:01:04|2009|   10|  27|  21|\n",
      "|     1|   1590|   2.5|1256677236|2009-10-27 21:00:36|2009|   10|  27|  21|\n",
      "|     1|   1591|   1.5|1256677475|2009-10-27 21:04:35|2009|   10|  27|  21|\n",
      "|     1|   2134|   4.5|1256677464|2009-10-27 21:04:24|2009|   10|  27|  21|\n",
      "|     1|   2478|   4.0|1256677239|2009-10-27 21:00:39|2009|   10|  27|  21|\n",
      "|     1|   2840|   3.0|1256677500|2009-10-27 21:05:00|2009|   10|  27|  21|\n",
      "|     1|   2986|   2.5|1256677496|2009-10-27 21:04:56|2009|   10|  27|  21|\n",
      "|     1|   3020|   4.0|1256677260|2009-10-27 21:01:00|2009|   10|  27|  21|\n",
      "|     1|   3424|   4.5|1256677444|2009-10-27 21:04:04|2009|   10|  27|  21|\n",
      "|     1|   3698|   3.5|1256677243|2009-10-27 21:00:43|2009|   10|  27|  21|\n",
      "|     1|   3826|   2.0|1256677210|2009-10-27 21:00:10|2009|   10|  27|  21|\n",
      "|     1|   3893|   3.5|1256677486|2009-10-27 21:04:46|2009|   10|  27|  21|\n",
      "|     2|    170|   3.5|1192913581|2007-10-20 20:53:01|2007|   10|  20|  20|\n",
      "|     2|    849|   3.5|1192913537|2007-10-20 20:52:17|2007|   10|  20|  20|\n",
      "|     2|   1186|   3.5|1192913611|2007-10-20 20:53:31|2007|   10|  20|  20|\n",
      "|     2|   1235|   3.0|1192913585|2007-10-20 20:53:05|2007|   10|  20|  20|\n",
      "+------+-------+------+----------+-------------------+----+-----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the date to day of the week\n",
    "\n",
    "df_ratings_final=df_ratings_final.withColumn(\"week_day_abb\", date_format(col(\"Date_of_rating\"), \"E\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----+-----+----+----+------------+\n",
      "|userId|movieId|rating|year|month|date|hour|week_day_abb|\n",
      "+------+-------+------+----+-----+----+----+------------+\n",
      "|     1|    307|   3.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|    481|   3.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|   1091|   1.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|   1257|   4.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|   1449|   4.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|   1590|   2.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|   1591|   1.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|   2134|   4.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|   2478|   4.0|2009|   10|  27|  21|         Tue|\n",
      "|     1|   2840|   3.0|2009|   10|  27|  21|         Tue|\n",
      "|     1|   2986|   2.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|   3020|   4.0|2009|   10|  27|  21|         Tue|\n",
      "|     1|   3424|   4.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|   3698|   3.5|2009|   10|  27|  21|         Tue|\n",
      "|     1|   3826|   2.0|2009|   10|  27|  21|         Tue|\n",
      "|     1|   3893|   3.5|2009|   10|  27|  21|         Tue|\n",
      "|     2|    170|   3.5|2007|   10|  20|  20|         Sat|\n",
      "|     2|    849|   3.5|2007|   10|  20|  20|         Sat|\n",
      "|     2|   1186|   3.5|2007|   10|  20|  20|         Sat|\n",
      "|     2|   1235|   3.0|2007|   10|  20|  20|         Sat|\n",
      "+------+-------+------+----+-----+----+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dropping timestamp and Date_of_rating because they are not required anymore\n",
    "\n",
    "df_ratings_final=df_ratings_final.drop(\"timestamp\").drop(\"Date_of_rating\")\n",
    "df_ratings_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_final = df_ratings_final. \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"01\" ,\"Jan\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"02\" ,\"Feb\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"03\" ,\"Mar\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"04\" ,\"Apr\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"05\" ,\"May\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"06\" ,\"Jun\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"07\" ,\"Jul\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"08\" ,\"Aug\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"09\" ,\"Sep\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"10\" ,\"Oct\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"11\" ,\"Nov\")). \\\n",
    "withColumn(\"month\", regexp_replace(\"month\" , \"12\" ,\"Dec\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----+-----+----+----+------------+\n",
      "|userId|movieId|rating|year|month|date|hour|week_day_abb|\n",
      "+------+-------+------+----+-----+----+----+------------+\n",
      "|     1|    307|   3.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|    481|   3.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   1091|   1.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   1257|   4.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   1449|   4.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   1590|   2.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   1591|   1.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   2134|   4.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   2478|   4.0|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   2840|   3.0|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   2986|   2.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   3020|   4.0|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   3424|   4.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   3698|   3.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   3826|   2.0|2009|  Oct|  27|  21|         Tue|\n",
      "|     1|   3893|   3.5|2009|  Oct|  27|  21|         Tue|\n",
      "|     2|    170|   3.5|2007|  Oct|  20|  20|         Sat|\n",
      "|     2|    849|   3.5|2007|  Oct|  20|  20|         Sat|\n",
      "|     2|   1186|   3.5|2007|  Oct|  20|  20|         Sat|\n",
      "|     2|   1235|   3.0|2007|  Oct|  20|  20|         Sat|\n",
      "+------+-------+------+----+-----+----+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert df_ratings into dataframe df_rating_summary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUWvwswgGM6l",
    "outputId": "af7205e1-f74a-47cb-9b3f-c96c1eff7ccc"
   },
   "outputs": [],
   "source": [
    "#Pre-processing\n",
    "#creating ratings_summary dataframe which contains avg rating and rating count group by movieId\n",
    "\n",
    "df_ratings_summary=df_ratings.groupby(\"movieId\") \\\n",
    "       .agg(mean(\"rating\").alias(\"avg_rating\"), \\\n",
    "       count(\"userId\").alias(\"rating_count\")) \\\n",
    "       .sort(asc(\"movieId\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+\n",
      "|movieId|        avg_rating|rating_count|\n",
      "+-------+------------------+------------+\n",
      "|      1| 3.886452155439497|       22594|\n",
      "|      2| 3.238923163208076|        8915|\n",
      "|      3|3.1868289877300615|        5216|\n",
      "|      4| 2.904433497536946|        1015|\n",
      "|      5|  3.09004647560031|        5164|\n",
      "|      6| 3.852959864449857|        9443|\n",
      "|      7|3.3775669861138273|        5113|\n",
      "|      8|3.1136363636363638|         506|\n",
      "|      9| 3.041392904073587|        1522|\n",
      "|     10|3.4277575205104833|       10970|\n",
      "|     11| 3.669363538295577|        6489|\n",
      "|     12|2.6782242384964356|        1543|\n",
      "|     13| 3.323394495412844|         654|\n",
      "|     14| 3.460434782608696|        2300|\n",
      "|     15|2.7338308457711444|        1005|\n",
      "|     16| 3.802249430523918|        7024|\n",
      "|     17| 3.956158287226365|        8314|\n",
      "|     18|3.4132231404958677|        2057|\n",
      "|     19| 2.642570036540804|        8210|\n",
      "|     20|2.8929032258064518|        1550|\n",
      "+-------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying ratings_summary\n",
    "df_ratings_summary.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and pre-processing of df_movies_metadata dataframe - additional metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete unwanted columns from df_movies_metadata dataframe\n",
    "\n",
    "df_movies_metadata=df_movies_metadata.drop(\"genres\").drop(\"id\") \\\n",
    "                                    .drop(\"imdb_id\").drop(\"original_title\") \\\n",
    "                                    .drop(\"overview\").drop(\"belongs_to_collection\") \\\n",
    "                                    .drop(\"poster_path\").drop(\"status\") \\\n",
    "                                    .drop(\"tagline\").drop(\"video\").drop(\"homepage\") \\\n",
    "                                    .drop(\"vote_average\").drop(\"vote_count\") \\\n",
    "                                    .drop(\"revenue\").drop(\"budget\").drop(\"spoken_languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning is not required for df_movies dataframe\n",
    "if some data were missing from the dataset we could easily drop them if the percentage were insignificant, Otherwise we could have replaced the values with mean data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating df_movies_ratings_summary_joined dataframe by inner joining df_movies and df_ratings_summary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "#Join df_movies and df_ratings_summary dataframe\n",
    "\n",
    "df_movies_ratings_summary_joined = df_movies.join(df_ratings_summary, \\\n",
    "df_movies[\"movieId\"] == df_ratings_summary[\"movieId\"], \\\n",
    "how=\"inner\").drop(df_movies[\"movieId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing of df_movies_ratings_summary_joined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+-------------------------------------------+-------+------------------+------------+\n",
      "|title                                |genres                                     |movieId|avg_rating        |rating_count|\n",
      "+-------------------------------------+-------------------------------------------+-------+------------------+------------+\n",
      "|Toy Story (1995)                     |Adventure|Animation|Children|Comedy|Fantasy|1      |3.886452155439497 |22594       |\n",
      "|Jumanji (1995)                       |Adventure|Children|Fantasy                 |2      |3.238923163208076 |8915        |\n",
      "|Grumpier Old Men (1995)              |Comedy|Romance                             |3      |3.1868289877300615|5216        |\n",
      "|Waiting to Exhale (1995)             |Comedy|Drama|Romance                       |4      |2.904433497536946 |1015        |\n",
      "|Father of the Bride Part II (1995)   |Comedy                                     |5      |3.09004647560031  |5164        |\n",
      "|Heat (1995)                          |Action|Crime|Thriller                      |6      |3.852959864449857 |9443        |\n",
      "|Sabrina (1995)                       |Comedy|Romance                             |7      |3.3775669861138273|5113        |\n",
      "|Tom and Huck (1995)                  |Adventure|Children                         |8      |3.1136363636363638|506         |\n",
      "|Sudden Death (1995)                  |Action                                     |9      |3.041392904073587 |1522        |\n",
      "|GoldenEye (1995)                     |Action|Adventure|Thriller                  |10     |3.4277575205104833|10970       |\n",
      "|American President, The (1995)       |Comedy|Drama|Romance                       |11     |3.669363538295577 |6489        |\n",
      "|Dracula: Dead and Loving It (1995)   |Comedy|Horror                              |12     |2.6782242384964356|1543        |\n",
      "|Balto (1995)                         |Adventure|Animation|Children               |13     |3.323394495412844 |654         |\n",
      "|Nixon (1995)                         |Drama                                      |14     |3.460434782608696 |2300        |\n",
      "|Cutthroat Island (1995)              |Action|Adventure|Romance                   |15     |2.7338308457711444|1005        |\n",
      "|Casino (1995)                        |Crime|Drama                                |16     |3.802249430523918 |7024        |\n",
      "|Sense and Sensibility (1995)         |Drama|Romance                              |17     |3.956158287226365 |8314        |\n",
      "|Four Rooms (1995)                    |Comedy                                     |18     |3.4132231404958677|2057        |\n",
      "|Ace Ventura: When Nature Calls (1995)|Comedy                                     |19     |2.642570036540804 |8210        |\n",
      "|Money Train (1995)                   |Action|Comedy|Crime|Drama|Thriller         |20     |2.8929032258064518|1550        |\n",
      "+-------------------------------------+-------------------------------------------+-------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pre-processing\n",
    "#remove any leading and lagging spaces using trim function\n",
    " \n",
    "df_movies_ratings_summary_joined = df_movies_ratings_summary_joined \\\n",
    ".withColumn('title', trim(df_movies_ratings_summary_joined.title))\n",
    "\n",
    "df_movies_ratings_summary_joined.show(truncate =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Removing the trailing year from the title column values using substring.\n",
    "\n",
    "df_movies_ratings_summary_joined = df_movies_ratings_summary_joined \\\n",
    ".withColumn(\"title\",expr(\"substring(title, 1, length(title)-7)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(df_movies_ratings_summary_joined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join df_movies_metadata with df_movies_ratings_summary_joined\n",
    "\n",
    "df_movies_ratings_summary_movies_metadata_joined = df_movies_ratings_summary_joined.join(df_movies_metadata, \\\n",
    "df_movies_ratings_summary_joined[\"title\"] == df_movies_metadata[\"title\"], \\\n",
    "how=\"inner\").drop(df_movies_ratings_summary_joined[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "table_showrows": "All"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28514"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies_ratings_summary_movies_metadata_joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df_movies_ratings_summary_movies_metadata_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+------------------+------------+-----+-----------------+----------+--------------------+--------------------+------------+-------+\n",
      "|               title|movieId|              genres|        avg_rating|rating_count|adult|original_language|popularity|production_companies|production_countries|release_date|runtime|\n",
      "+--------------------+-------+--------------------+------------------+------------+-----+-----------------+----------+--------------------+--------------------+------------+-------+\n",
      "|40 Guns to Apache...|  72163|Adventure|Romance...|3.3333333333333335|           3|False|               en|  1.158998|[{'name': 'Columb...|[{'iso_3166_1': '...|  1967-05-01|   95.0|\n",
      "|A Brave Heart: Th...| 149534|         Documentary|               3.5|           1|False|               en|  0.161354|                  []|[{'iso_3166_1': '...|  2015-03-14|   90.0|\n",
      "|   A Cry in the Wild| 121141|Action|Adventure|...|2.6666666666666665|           3|False|               en|   0.80227|                  []|                  []|  1990-06-01|   82.0|\n",
      "|All The Days Befo...| 156921|Comedy|Drama|Romance|              4.25|           2|False|               en|  0.348432|[{'name': 'Kangoo...|                  []|  2007-04-01|  100.0|\n",
      "|             Amateur|    149|Crime|Drama|Thriller|3.6770573566084788|         401|False|               en|  1.759012|[{'name': 'Channe...|[{'iso_3166_1': '...|  1994-08-05|  105.0|\n",
      "|Amazing Journey: ...|  68273|         Documentary| 3.857142857142857|           7|False|               en|   0.05157|                  []|                  []|  2007-09-14|  237.0|\n",
      "|  Beer for My Horses| 128167|       Action|Comedy|2.3333333333333335|           6|False|               en|  2.033354|[{'name': 'Show D...|[{'iso_3166_1': '...|  2008-08-08|   86.0|\n",
      "|Before I Go to Sleep| 114007|    Mystery|Thriller| 3.481818181818182|         110|False|               en| 14.921298|[{'name': 'Studio...|[{'iso_3166_1': '...|  2014-09-03|   92.0|\n",
      "|         Big Nothing|  52606|Comedy|Crime|Thri...|3.3512396694214877|         121|False|               en| 11.802069|                  []|[{'iso_3166_1': '...|  2006-12-01|   86.0|\n",
      "|       Boy Eats Girl|  69211|       Comedy|Horror|2.3636363636363638|          11|False|               en|  4.912303|[{'name': 'Elemen...|[{'iso_3166_1': '...|  2005-06-07|   80.0|\n",
      "|              Breezy|   8696|       Drama|Romance|               3.1|          15|False|               en|  2.090768|[{'name': 'Malpas...|[{'iso_3166_1': '...|  1973-11-18|  108.0|\n",
      "|   Charlie's Country| 112735|               Drama|               4.5|           2|False|               en|  0.912033|[{'name': 'Vertig...|[{'iso_3166_1': '...|  2013-10-12|  108.0|\n",
      "|Continental, a Fi...| 148089|        Comedy|Drama|               3.5|           1|False|               fr|  0.125624|[{'name': 'Micro ...|[{'iso_3166_1': '...|  2007-11-09|  103.0|\n",
      "|              Crisis| 116311|      Drama|Thriller|              3.25|           2|False|               sv|  0.832827|[{'name': 'Svensk...|[{'iso_3166_1': '...|  1946-02-25|   93.0|\n",
      "|       Crossing Over|  68552|               Drama| 3.297872340425532|          47|False|               en|  6.036408|[{'name': 'Kenned...|[{'iso_3166_1': '...|  2009-02-27|  113.0|\n",
      "|           Da grande| 134415|  (no genres listed)|               3.5|           1|False|               it|  0.003977|[{'name': 'Reteit...|[{'iso_3166_1': '...|  1987-12-23|    0.0|\n",
      "|         Deep Rising|   1762|Action|Horror|Sci-Fi|      2.7978515625|         512|False|               en|  6.922458|[{'name': 'Hollyw...|[{'iso_3166_1': '...|  1998-01-30|  106.0|\n",
      "|Diary of a Chambe...| 128608|               Drama|2.6818181818181817|          11|False|               fr|  3.003084|[{'name': 'Filmso...|[{'iso_3166_1': '...|  1964-01-01|  101.0|\n",
      "|Diary of a Chambe...| 128608|               Drama|2.6818181818181817|          11|False|               fr|  2.967943|[{'name': 'Les Fi...|[{'iso_3166_1': '...|  2015-02-07|   96.0|\n",
      "|            Disraeli|  83376|               Drama|               2.5|           2|False|               en|  0.401707|[{'name': 'Warner...|[{'iso_3166_1': '...|  1929-11-01|   90.0|\n",
      "+--------------------+-------+--------------------+------------------+------------+-----+-----------------+----------+--------------------+--------------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rearranging column positions of df_all_data_movies dataframe\n",
    "\n",
    "df_all_data_movies = df_movies_ratings_summary_movies_metadata_joined \\\n",
    ".select(\"title\",\"movieId\",\"genres\",\"avg_rating\",\"rating_count\",\"adult\", \\\n",
    "        \"original_language\",\"popularity\",\"production_companies\", \\\n",
    "        \"production_countries\",\"release_date\",\"runtime\")\n",
    "\n",
    "\n",
    "df_all_data_movies.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using externam dataset for language codes to replace original language codes to actual language by joining df_all_data_movies with df_language_codes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing language codes with language\n",
    "\n",
    "df_all_data_movies = df_all_data_movies.join(df_language_codes, \\\n",
    "df_all_data_movies[\"original_language\"] == df_language_codes[\"code\"], \\\n",
    "how=\"inner\").drop(df_all_data_movies[\"original_language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- rating_count: long (nullable = false)\n",
      " |-- adult: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove unwanted columns\n",
    "df_all_data_movies = df_all_data_movies.drop(\"code\")\n",
    "df_all_data_movies.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "filter": "{\"field\": \"release_year\", \"constraint\": \"None\", \"value\": \"22\", \"case_matter\": \"true\", \"regex\": \"false\"}",
      "handlerId": "histogram",
      "no_margin": "true"
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all_data_movies=df_all_data_movies.withColumn(\"runtime\",col(\"runtime\").cast(\"int\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "binsize": "158",
      "chartsize": "86",
      "handlerId": "scatterPlot",
      "keyFields": "avg_rating",
      "mpld3": "false",
      "rendererId": "seaborn",
      "rowCount": "50000",
      "title": "Histogram of movie runtime by frequency",
      "valueFields": "runtime"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(df_all_data_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- rating_count: long (nullable = false)\n",
      " |-- adult: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all_data_movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "display(df_all_data_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records = 39787\n",
      "Total columns = 3\n",
      "+++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++\n",
      "1.Column<b'movieId'>\n",
      "  Missing Values = \n",
      "+------------------------------------------------+\n",
      "|count(CASE WHEN (movieId IS NULL) THEN true END)|\n",
      "+------------------------------------------------+\n",
      "|                                               0|\n",
      "+------------------------------------------------+\n",
      "\n",
      "2.Column<b'avg_rating'>\n",
      "  Missing Values = \n",
      "+---------------------------------------------------+\n",
      "|count(CASE WHEN (avg_rating IS NULL) THEN true END)|\n",
      "+---------------------------------------------------+\n",
      "|                                                  0|\n",
      "+---------------------------------------------------+\n",
      "\n",
      "3.Column<b'rating_count'>\n",
      "  Missing Values = \n",
      "+-----------------------------------------------------+\n",
      "|count(CASE WHEN (rating_count IS NULL) THEN true END)|\n",
      "+-----------------------------------------------------+\n",
      "|                                                    0|\n",
      "+-----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize Counter to 0\n",
    "i = 0 \n",
    "\n",
    "#Total records in the df_movies dataframe\n",
    "\n",
    "total = df_ratings_summary.count()\n",
    "\n",
    "print(\"Total Records = \" + str(total))\n",
    "\n",
    "#Prints the total number of column\n",
    "\n",
    "print(\"Total columns = \" + str(len(df_ratings_summary.columns)))\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "#while Loop used here to display the count of  each column's missing values \n",
    "\n",
    "while i < len(df_ratings_summary.columns):                             \n",
    "#Loop which checks every column\n",
    "    print(str(i+1) + \".\" + str(df_ratings_summary[i]))\n",
    "    print(\"  Missing Values = \") \n",
    "   \n",
    "    missingvalue1 = df_ratings_summary \\\n",
    "    .select([count(when(df_ratings_summary[i].isNull(),True))]).show() \n",
    "    i = i+1 \n",
    "    #Counter is incremented by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking data after cleaning and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final dataframe is df_all_data_movies. This dataframe contains all the required columns data after multiple join operation and data cleaning. This dataframe has only been created for visualization and exploratory data analysis.\n",
    "Main machine learning model will work on the orimary dataset which is df_ratings dataframe. This dataframe is clean and do not require any pre-processing or cleaning activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28389"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of records\n",
    "df_all_data_movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- rating_count: long (nullable = false)\n",
      " |-- adult: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print schema details\n",
    "df_all_data_movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records = 28389\n",
      "Total columns = 12\n",
      "+++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++\n",
      "1.Column<b'title'>\n",
      "  Missing Values = \n",
      "+----------------------------------------------+\n",
      "|count(CASE WHEN (title IS NULL) THEN true END)|\n",
      "+----------------------------------------------+\n",
      "|                                             0|\n",
      "+----------------------------------------------+\n",
      "\n",
      "2.Column<b'movieId'>\n",
      "  Missing Values = \n",
      "+------------------------------------------------+\n",
      "|count(CASE WHEN (movieId IS NULL) THEN true END)|\n",
      "+------------------------------------------------+\n",
      "|                                               0|\n",
      "+------------------------------------------------+\n",
      "\n",
      "3.Column<b'genres'>\n",
      "  Missing Values = \n",
      "+-----------------------------------------------+\n",
      "|count(CASE WHEN (genres IS NULL) THEN true END)|\n",
      "+-----------------------------------------------+\n",
      "|                                              0|\n",
      "+-----------------------------------------------+\n",
      "\n",
      "4.Column<b'avg_rating'>\n",
      "  Missing Values = \n",
      "+---------------------------------------------------+\n",
      "|count(CASE WHEN (avg_rating IS NULL) THEN true END)|\n",
      "+---------------------------------------------------+\n",
      "|                                                  0|\n",
      "+---------------------------------------------------+\n",
      "\n",
      "5.Column<b'rating_count'>\n",
      "  Missing Values = \n",
      "+-----------------------------------------------------+\n",
      "|count(CASE WHEN (rating_count IS NULL) THEN true END)|\n",
      "+-----------------------------------------------------+\n",
      "|                                                    0|\n",
      "+-----------------------------------------------------+\n",
      "\n",
      "6.Column<b'adult'>\n",
      "  Missing Values = \n",
      "+----------------------------------------------+\n",
      "|count(CASE WHEN (adult IS NULL) THEN true END)|\n",
      "+----------------------------------------------+\n",
      "|                                             0|\n",
      "+----------------------------------------------+\n",
      "\n",
      "7.Column<b'popularity'>\n",
      "  Missing Values = \n",
      "+---------------------------------------------------+\n",
      "|count(CASE WHEN (popularity IS NULL) THEN true END)|\n",
      "+---------------------------------------------------+\n",
      "|                                                  0|\n",
      "+---------------------------------------------------+\n",
      "\n",
      "8.Column<b'production_companies'>\n",
      "  Missing Values = \n",
      "+-------------------------------------------------------------+\n",
      "|count(CASE WHEN (production_companies IS NULL) THEN true END)|\n",
      "+-------------------------------------------------------------+\n",
      "|                                                            0|\n",
      "+-------------------------------------------------------------+\n",
      "\n",
      "9.Column<b'production_countries'>\n",
      "  Missing Values = \n",
      "+-------------------------------------------------------------+\n",
      "|count(CASE WHEN (production_countries IS NULL) THEN true END)|\n",
      "+-------------------------------------------------------------+\n",
      "|                                                            0|\n",
      "+-------------------------------------------------------------+\n",
      "\n",
      "10.Column<b'release_date'>\n",
      "  Missing Values = \n",
      "+-----------------------------------------------------+\n",
      "|count(CASE WHEN (release_date IS NULL) THEN true END)|\n",
      "+-----------------------------------------------------+\n",
      "|                                                   11|\n",
      "+-----------------------------------------------------+\n",
      "\n",
      "11.Column<b'runtime'>\n",
      "  Missing Values = \n",
      "+------------------------------------------------+\n",
      "|count(CASE WHEN (runtime IS NULL) THEN true END)|\n",
      "+------------------------------------------------+\n",
      "|                                              81|\n",
      "+------------------------------------------------+\n",
      "\n",
      "12.Column<b'language'>\n",
      "  Missing Values = \n",
      "+-------------------------------------------------+\n",
      "|count(CASE WHEN (language IS NULL) THEN true END)|\n",
      "+-------------------------------------------------+\n",
      "|                                                0|\n",
      "+-------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize Counter to 0\n",
    "i = 0 \n",
    "\n",
    "#Total records in the df_ratings dataframe\n",
    "\n",
    "total = df_all_data_movies.count()\n",
    "\n",
    "print(\"Total Records = \" + str(total))\n",
    "\n",
    "#Prints the total number of column\n",
    "\n",
    "print(\"Total columns = \" + str(len(df_all_data_movies.columns)))\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "#while Loop used here to display the count of  each column's missing values \n",
    "\n",
    "while i < len(df_all_data_movies.columns):                             \n",
    "#Loop which checks every column\n",
    "    print(str(i+1) + \".\" + str(df_all_data_movies[i]))\n",
    "    print(\"  Missing Values = \") \n",
    "   \n",
    "    missingvalue1 = df_all_data_movies.select([count(when(df_all_data_movies[i].isNull(),True))]).show() \n",
    "    i = i+1 \n",
    "    #Counter is incremented by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "handlerId": "barChart",
      "keyFields": "month",
      "legend": "true",
      "rendererId": "bokeh",
      "sortby": "Values ASC",
      "timeseries": "false",
      "title": "Rating count by month ",
      "valueFields": "userId"
     }
    }
   },
   "outputs": [],
   "source": [
    "#Rating count by month \n",
    "display(df_ratings_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "handlerId": "barChart",
      "keyFields": "week_day_abb",
      "rendererId": "bokeh",
      "sortby": "Values ASC",
      "title": "Rating count by days of week ",
      "valueFields": "rating"
     }
    }
   },
   "outputs": [],
   "source": [
    "#Rating count by days of week \n",
    "display(df_ratings_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "handlerId": "lineChart",
      "keyFields": "hour",
      "title": "#Rating count by hour of the day",
      "valueFields": "rating"
     }
    }
   },
   "outputs": [],
   "source": [
    "#Rating count by hour of the day\n",
    "display(df_ratings_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "pieChart",
      "keyFields": "month",
      "legend": "false",
      "rendererId": "bokeh",
      "sortby": "Values DESC",
      "valueFields": "rating"
     }
    }
   },
   "outputs": [],
   "source": [
    "#Rating count by month - pie chart\n",
    "display(df_ratings_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "binsize": "189",
      "handlerId": "scatterPlot",
      "kde": "true",
      "keyFields": "avg_rating",
      "mpld3": "false",
      "rendererId": "seaborn",
      "rowCount": "500000",
      "title": "Average rating vs count of rating",
      "valueFields": "rating_count"
     }
    }
   },
   "outputs": [],
   "source": [
    "#Average rating vs count of rating\n",
    "display(df_ratings_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|            genres|count|\n",
      "+------------------+-----+\n",
      "|             Crime| 5105|\n",
      "|           Romance| 7412|\n",
      "|          Thriller| 8216|\n",
      "|         Adventure| 4067|\n",
      "|             Drama|24144|\n",
      "|               War| 1820|\n",
      "|       Documentary| 5118|\n",
      "|           Fantasy| 2637|\n",
      "|           Mystery| 2773|\n",
      "|           Musical| 1113|\n",
      "|         Animation| 2663|\n",
      "|         Film-Noir|  364|\n",
      "|(no genres listed)| 4266|\n",
      "|              IMAX|  197|\n",
      "|            Horror| 5555|\n",
      "|           Western| 1378|\n",
      "|            Comedy|15956|\n",
      "|          Children| 2749|\n",
      "|            Action| 7130|\n",
      "|            Sci-Fi| 3444|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4266"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Movie count by genres\n",
    "\n",
    "joindf=df_movies.join(df_ratings,['movieId'], how='inner').drop(df_ratings['movieId'])\n",
    "df_movie_by_genres = df_movies.withColumn(\"genres\", explode(split(\"genres\",\"[|]\")))\n",
    "df_movie_by_genres.groupBy(\"genres\").count().show()\n",
    "\n",
    "#movie count where genre is not listed\n",
    "df_movie_by_genres.filter(df_movies.genres==\"(no genres listed)\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "handlerId": "barChart",
      "keyFields": "genres",
      "legend": "true",
      "orientation": "horizontal",
      "rendererId": "matplotlib",
      "sortby": "Values ASC",
      "title": "movie count by genres",
      "valueFields": "movieId"
     }
    }
   },
   "outputs": [],
   "source": [
    "#movie count by genres\n",
    "\n",
    "display(df_movie_by_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "handlerId": "lineChart",
      "keyFields": "release_year",
      "legend": "false",
      "logx": "false",
      "logy": "false",
      "rendererId": "bokeh",
      "timeseries": "true",
      "title": "Released movie count by year - time series  ",
      "valueFields": "movieId"
     }
    }
   },
   "outputs": [],
   "source": [
    "#released movie count by year - time series  \n",
    "\n",
    "display(df_all_data_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "binsize": "195",
      "handlerId": "histogram",
      "histoChartType": "subplots",
      "rendererId": "seaborn",
      "rowCount": "500000",
      "title": "Histogram of movies by runtime",
      "valueFields": "runtime"
     }
    }
   },
   "outputs": [],
   "source": [
    "#histogram of movies by runtime\n",
    "\n",
    "display(df_all_data_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "filter": "{\"field\": \"language\", \"constraint\": \"None\", \"value\": \"english\", \"case_matter\": \"false\", \"regex\": \"false\"}",
      "handlerId": "pieChart",
      "keyFields": "language",
      "no_margin": "true",
      "valueFields": "movieId"
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "display(df_all_data_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#describe data statistics of df_all_data_movies dataframe\n",
    "\n",
    "display(df_all_data_movies.describe().show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBoUiiyGUQR8"
   },
   "source": [
    "# Machine Learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting df_ratings dataframe into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "av__AbEqGy93"
   },
   "outputs": [],
   "source": [
    "(training,test)=df_ratings.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rbbzbJwUY8a"
   },
   "source": [
    "Alternating Least Squares (ALS) is an approach of matrix factorisation which attempts to estimate the ratings matrix as the product of two lower-rank matrices.It's an iterative process. During each iteration, one of the factor matrices is kept constant, while the other is solved for using least squares. The newly-solved factor matrix is then held constant while solving for the other factor matrix.\n",
    "\n",
    "ALS can overcome two big challenges-\n",
    "- Sparsity- Not all items will be rated so there will be lot of blank infrmation in user item matrix.\n",
    "- Cold start problem- Addition of a new user or a new item where both do not have history in terms of ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9MuHB0EZaHq"
   },
   "source": [
    "Model parameters for ALS are-\n",
    "- maxIter- number of iterations ALS will do.\n",
    "- regParam- the regularization parameter in ALS \n",
    "- userCol,itemCol and ratingCol are the setting features\n",
    "- coldStartStrategy - when prediction is run and a model is not trained for a particular user/ ratings or items are not found for a user then it will drop those users if given “drop” as parameter’s value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "gGnk4X6nG_9s"
   },
   "outputs": [],
   "source": [
    "als=ALS(maxIter=5,regParam=0.01,userCol=\"userId\",itemCol=\"movieId\",ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
    "model=als.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o516.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 287.0 failed 1 times, most recent failure: Lost task 0.0 in stage 287.0 (TID 14149, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:97)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:120)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:135)\n\tat org.apache.spark.io.LZ4CompressionCodec.compressedOutputStream(CompressionCodec.scala:117)\n\tat org.apache.spark.serializer.SerializerManager.wrapForCompression(SerializerManager.scala:156)\n\tat org.apache.spark.serializer.SerializerManager.wrapStream(SerializerManager.scala:131)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:120)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1098)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1092)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1161)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1137)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.summary$lzycompute(RegressionMetrics.scala:57)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.summary(RegressionMetrics.scala:54)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.SSerr$lzycompute(RegressionMetrics.scala:65)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.SSerr(RegressionMetrics.scala:65)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.meanSquaredError(RegressionMetrics.scala:100)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.rootMeanSquaredError(RegressionMetrics.scala:109)\n\tat org.apache.spark.ml.evaluation.RegressionEvaluator.evaluate(RegressionEvaluator.scala:86)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:97)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:120)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:135)\n\tat org.apache.spark.io.LZ4CompressionCodec.compressedOutputStream(CompressionCodec.scala:117)\n\tat org.apache.spark.serializer.SerializerManager.wrapForCompression(SerializerManager.scala:156)\n\tat org.apache.spark.serializer.SerializerManager.wrapStream(SerializerManager.scala:131)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:120)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-300f64d04804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRegressionEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmse\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrmse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark2.4.3/python/lib/pyspark.zip/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark2.4.3/python/lib/pyspark.zip/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark2.4.3/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark2.4.3/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark2.4.3/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o516.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 287.0 failed 1 times, most recent failure: Lost task 0.0 in stage 287.0 (TID 14149, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:97)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:120)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:135)\n\tat org.apache.spark.io.LZ4CompressionCodec.compressedOutputStream(CompressionCodec.scala:117)\n\tat org.apache.spark.serializer.SerializerManager.wrapForCompression(SerializerManager.scala:156)\n\tat org.apache.spark.serializer.SerializerManager.wrapStream(SerializerManager.scala:131)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:120)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1098)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1092)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1161)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1137)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.summary$lzycompute(RegressionMetrics.scala:57)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.summary(RegressionMetrics.scala:54)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.SSerr$lzycompute(RegressionMetrics.scala:65)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.SSerr(RegressionMetrics.scala:65)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.meanSquaredError(RegressionMetrics.scala:100)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.rootMeanSquaredError(RegressionMetrics.scala:109)\n\tat org.apache.spark.ml.evaluation.RegressionEvaluator.evaluate(RegressionEvaluator.scala:86)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:97)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:120)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.<init>(LZ4BlockOutputStream.java:135)\n\tat org.apache.spark.io.LZ4CompressionCodec.compressedOutputStream(CompressionCodec.scala:117)\n\tat org.apache.spark.serializer.SerializerManager.wrapForCompression(SerializerManager.scala:156)\n\tat org.apache.spark.serializer.SerializerManager.wrapStream(SerializerManager.scala:131)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:120)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "predictions=model.transform(test)\n",
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "print(\"RMSE=\"+str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWcib3rrarxa"
   },
   "source": [
    "Let's try hyper parameter tuning-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xnt0b2ARBAwM"
   },
   "outputs": [],
   "source": [
    "# tuning hyper-parameter\n",
    "\n",
    "als=ALS(userCol=\"userId\",itemCol=\"movieId\",ratingCol=\"rating\",coldStartStrategy=\"drop\",nonnegative=True)\n",
    "\n",
    "\n",
    "# creating a parameter grid for all combination of ranks, max iterations and regularization parameters\n",
    "param_grid=ParamGridBuilder().addGrid(als.rank,[5,10,15]) \\\n",
    ".addGrid(als.maxIter,[5,10,15]).addGrid(als.regParam,[0.01,0.05,0.1]).build()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating rmse \n",
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "tvs=TrainValidationSplit(estimator=als,estimatorParamMaps=param_grid,evaluator=evaluator)\n",
    "\n",
    "#trainig the model with training data\n",
    "model=tvs.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tU8QynUQD6wx"
   },
   "outputs": [],
   "source": [
    "#calculating RMSE using best model\n",
    "\n",
    "best_model=model.bestModel\n",
    "predictions=best_model.transform(test)\n",
    "rmse=evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTE9I1KGEXfI",
    "outputId": "d85c5ada-98b2-4060-afe9-e14956921587"
   },
   "outputs": [],
   "source": [
    "#printing RMSE, Rank, Max interation and regularization parameter using best model\n",
    "\n",
    "print(\"RMSE=\"+str(rmse))\n",
    "print(\"Rank=\"+str(best_model.rank))\n",
    "print(\"MaxIter=\"+str(best_model._java_obj.parent().getMaxIter()))\n",
    "print(\"RegParam=\"+str(best_model._java_obj.parent().getRegParam()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QR0eXbdMbqbD"
   },
   "source": [
    "Clearly best model out performed our previous model as RMSE dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em5Dnl5tb3Om"
   },
   "source": [
    "Recommendation for all userId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jd1lTQ3rIcHs",
    "outputId": "e60a9e8b-dd62-40e3-c111-e754571c9ca6",
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "a=best_model.recommendForAllUsers(10).sort(\"userId\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XREs6Ytxc-4e"
   },
   "source": [
    "Comparison of prediction vs actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0lVE-8kMSeW",
    "outputId": "85adbc11-8e38-4d6c-b82c-8436580707e7"
   },
   "outputs": [],
   "source": [
    "predictions.sort(\"userId\",\"rating\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FdouIvOcQRr"
   },
   "source": [
    "Well all user recomendation output is difficult to expain because of its format, Let's create a function to make it more explainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5P7wxroRTX4K"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_rec(rec):\n",
    "  rec=rec.select(\"userId\",explode(rec.recommendations))\n",
    "  rec=rec.select(\"col.*\",\"*\")\n",
    "  rating_mat=rec.select([\"userId\",\"movieId\",\"rating\"])\n",
    "  return rating_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CXOJ1jNfHO2",
    "outputId": "6d607401-e5ea-4c0c-f615-7805b76d31a8"
   },
   "outputs": [],
   "source": [
    "rating_mat=get_rec(best_model.recommendForAllUsers(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBjTSQy8mohy",
    "outputId": "b9b9dec3-bc13-46fe-fa85-6ede94dd046e"
   },
   "outputs": [],
   "source": [
    "rating_mat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKuHfnDgch3d"
   },
   "source": [
    "Lets merge this result with the movie data to get a clear picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFxrJVy3nRz1"
   },
   "outputs": [],
   "source": [
    "final_df=rating_mat.join(df_movies,['movieId'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBzLxJKVrCt7",
    "outputId": "8336c085-af16-4d5c-a7a4-85a535a4dc99"
   },
   "outputs": [],
   "source": [
    "final_df.filter(\"userId=10\").orderBy(final_df[\"rating\"].desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md_9MPMDcrRd"
   },
   "source": [
    "Now lets merge the rating data with the movie data and compare the result outcome with the actuals for a random user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIhPj4g_rXMl",
    "outputId": "6ef5cdec-991b-442f-b7de-4558d5292271"
   },
   "outputs": [],
   "source": [
    "df_test=df_movies.join(df_ratings,['movieId'],how='left')\n",
    "df_test.filter(\"userId=10\").orderBy(df_test[\"rating\"].desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgTqdKHXdG-6"
   },
   "source": [
    "As we can see user 5 mostly liked comedy, romance and drama movies in actual and in our recomendation also he is mostly getting comedy movie suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "\n",
    "\n",
    "predictions.join(df_movies,\"movieId\").select(\"userId\",\"title\",\"genres\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#showing movie recommendation for perticular user and links by joining the df_linkd dataframe with predictions \n",
    "\n",
    "for_one_user=predictions.filter(col(\"userId\")==10).join(df_movies, \"movieId\") \\\n",
    ".join(df_links, \"movieId\").select(\"userId\",\"title\",\"genres\",\"prediction\",\"tmdbId\",)\n",
    "display(for_one_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating top three movie recommendations and the links for the movie homepage in TMDB\n",
    "url=\"https://www.themoviedb.org/movie/\"\n",
    "for movie in for_one_user.take(3):\n",
    "    movieURL=url+str(movie.tmdbId)\n",
    "    print(movieURL)\n",
    "    print(movie.title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 5 movie recommendation for each user\n",
    "\n",
    "userRecommends = best_model.recommendForAllUsers(5)\n",
    "\n",
    "userRecommends.select(\"userId\",\"recommendations.movieId\").show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 5 user recommendation for each movie\n",
    "\n",
    "itemRecommends = best_model.recommendForAllItems(5)\n",
    "\n",
    "itemRecommends.select(\"movieId\",\"recommendations.userId\").show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity based recommendation when there are no prior existance of the user or item(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General popular movies\n",
    "\n",
    "popular_movies=df_all_data_movies.sort(\"popularity\")\n",
    "popular_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Movie_Lens",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
